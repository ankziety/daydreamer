# Daydreamer Research AI Configuration
# This file configures the research chat system for different use cases

[ai_models]
# Model preference order: "ollama", "transformers", "api", "auto"
# auto = try ollama first, then transformers, then minimal generator
model_preference = ollama

# Ollama settings (for local open models)
# The system will automatically detect available models and choose the best one
# You can specify your preferred model here, or leave as 'auto' for automatic selection
ollama_model = llama3.2:latest
ollama_host = localhost:11434

# Examples of specific models you might want to use:
# ollama_model = gemma3n:e4b     # High-end variant
# ollama_model = gemma3n:3b      # Standard model  
# ollama_model = llama3.2:8b     # Larger Llama model

# API settings (for premium models when available)
# Uncomment and add your API keys when ready to use premium models
# openai_api_key = your_openai_key_here
# anthropic_api_key = your_anthropic_key_here
# preferred_api_model = gpt-4

# Transformers fallback settings
transformers_model = gpt2
use_gpu = false

[research_settings]
# Chain of thought configuration
enable_chain_of_thought = true
cot_detail_level = standard  # minimal, standard, detailed

# Daydreaming configuration
daydream_probability = 0.45  # 45% chance per interaction
max_daydream_memories = 100

# Adaptive learning settings
enable_adaptive_learning = true
pattern_learning_rate = 0.003
user_profile_tracking = true

# Memory system settings
enable_memory_persistence = true
max_conversation_history = 1000

[interface_settings]
# Research transparency settings
show_system_info = true
show_model_versions = true
show_processing_times = true
show_confidence_scores = true

# DMN integration settings
enable_dmn_integration = true
enable_intrusive_thoughts = true

# Logging and research data
enable_conversation_logging = true
research_data_retention = 90  # days